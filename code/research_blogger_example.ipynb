{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "933c3b6b-7a65-4fe0-aebc-3f0521bd3dc6",
   "metadata": {},
   "source": [
    "## Research Blogger: Automated Paper Summarization and Social Media Posting \n",
    "### This script fetches the latest AI research paper from arXiv, generates a blog post summary, creates a GitHub Pages post, and shares it on Threads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36da3e68-07b5-492a-8795-c8bf25746df0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "## Processing: Multi-View and Multi-Scale Alignment for Contrastive Language-Image Pre-training in Mammography"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Original Paper: [http://arxiv.org/abs/2409.18119v1](http://arxiv.org/abs/2409.18119v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you ready to revolutionize mammography with cutting-edge technology? A recent scientific paper by Yuexi Du, John Onofrey, and Nicha C. Dvornek has unveiled a groundbreaking approach to enhance contrastive language-image pre-training (CLIP) specifically for mammography. Let's dive into the exciting world of medical image analysis and explore the implications of this innovative research.\n",
       "\n",
       "In simple terms, the researchers have developed a method called Multi-View and Multi-Scale Alignment (MaMA) to improve the performance of CLIP in analyzing mammography images. Mammograms, which are X-ray images of the breast, present unique challenges such as limited labeled data, high-resolution images with small areas of interest, and data imbalance. To tackle these issues, the MaMA method leverages the multi-view nature of mammography and incorporates a specialized local alignment module to focus on detailed features in high-resolution images.\n",
       "\n",
       "But what does this mean for real-world applications? The implications are profound. By enhancing the capabilities of CLIP in mammography analysis, healthcare professionals can potentially improve early detection of breast cancer and other abnormalities. With more accurate and efficient image analysis tools, radiologists and clinicians can make better-informed decisions, leading to earlier interventions and improved patient outcomes.\n",
       "\n",
       "Furthermore, the MaMA method offers a parameter-efficient fine-tuning approach, allowing for effective utilization of large language models pre-trained with medical knowledge. This approach addresses the data limitations in mammography and demonstrates superior performance compared to existing methods, even with a significantly smaller model size.\n",
       "\n",
       "Imagine a future where mammograms are analyzed with unprecedented accuracy and efficiency, thanks to advanced AI technologies like MaMA. This research not only pushes the boundaries of medical imaging but also highlights the potential of AI in revolutionizing healthcare diagnostics.\n",
       "\n",
       "In conclusion, the study by Du, Onofrey, and Dvornek opens up new possibilities for enhancing mammography analysis through multi-view and multi-scale alignment techniques. As we look towards a future where technology plays an increasingly vital role in healthcare, this research serves as a beacon of hope for more effective and accessible diagnostic tools in the fight against breast cancer and other diseases. Exciting times lie ahead in the intersection of AI and medical imaging, where innovation paves the way for a healthier tomorrow."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blog post already exists: 2024-09-28-multi-view-and-multi-scale-alignment-for-contrasti.md\n",
      "Failed to create blog post on GitHub or post already exists.\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Threads Post:\n",
       "üî¨‚ú® Exciting new research alert! A study on enhancing contrastive language-image pre-training in mammography through multi-view and multi-scale alignment has just been published. üì∏üîç Dive into the details to learn how this innovative approach could revolutionize early breast cancer detection. Read more: [URL] #BreastCancer #MedicalImaging #ResearchDiscovery üåüüìö Read more: https://porkpy.github.io/research_blogger/2024/09/28/multi-view-and-multi-scale-alignment-for-contrasti"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Media Container Status Code: 200\n",
      "Waiting 30 seconds before publishing...\n",
      "Publish Thread Status Code: 200\n",
      "Successfully posted to Threads!\n",
      "Successfully posted to Threads!\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import openai\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "# Configuration\n",
    "THREADS_USER_ID = 'your-Threads-user-id'\n",
    "THREADS_ACCESS_TOKEN = \"your-Threads-access-token\"\n",
    "APP_SECRET = 'your-Threads-secret-key'\n",
    "OPENAI_API_KEY = \"your-openAI-key\"\n",
    "GITHUB_TOKEN = \"your-github-access-token\"\n",
    "GITHUB_REPO = \"your-github-username/repo-name\"\n",
    "GITHUB_PAGES_SITE = 'username.github.io/repo-name'  # e.g. porkpy.github.io/research_blogger\n",
    "\n",
    "# Set up OpenAI API client\n",
    "openai.api_key = OPENAI_API_KEY\n",
    "\n",
    "def fetch_latest_paper(category):\n",
    "    \"\"\"\n",
    "    Fetches the latest paper from arXiv in the specified category.\n",
    "    \n",
    "    Args:\n",
    "    category (str): The arXiv category to search in (e.g., \"cs.AI\" for Artificial Intelligence)\n",
    "    \n",
    "    Returns:\n",
    "    arxiv.Result or None: The latest paper if found within the last week, otherwise None\n",
    "    \"\"\"\n",
    "    client = arxiv.Client()\n",
    "    last_week = datetime.now(timezone.utc) - timedelta(days=7)\n",
    "    search = arxiv.Search(\n",
    "        query=f\"cat:{category}\",\n",
    "        max_results=1,\n",
    "        sort_by=arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    results = list(client.results(search))\n",
    "    if results and results[0].published.replace(tzinfo=timezone.utc) > last_week:\n",
    "        return results[0]\n",
    "    return None\n",
    "\n",
    "def generate_blog_post(paper):\n",
    "    \"\"\"\n",
    "    Generates a blog post summary of the given paper using OpenAI's GPT model.\n",
    "    \n",
    "    Args:\n",
    "    paper (arxiv.Result): The paper to summarize\n",
    "    \n",
    "    Returns:\n",
    "    str or None: The generated blog post content, or None if generation fails\n",
    "    \"\"\"\n",
    "    authors = ', '.join([author.name for author in paper.authors])\n",
    "    prompt = f\"\"\"Write an engaging blog post about the following scientific paper:\n",
    "\n",
    "Title: {paper.title}\n",
    "Authors: {authors}\n",
    "Abstract: {paper.summary}\n",
    "\n",
    "The blog post should:\n",
    "1. Explain the main findings in simple terms\n",
    "2. Discuss potential real-world implications\n",
    "3. Be engaging and accessible to a general audience\n",
    "4. Be around 300-400 words long\n",
    "\n",
    "Blog Post:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes engaging blog posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=500,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating blog post: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_threads_post(paper, blog_post_url):\n",
    "    \"\"\"\n",
    "    Generates a short post for Threads about the given paper.\n",
    "    \n",
    "    Args:\n",
    "    paper (arxiv.Result): The paper to create a post about\n",
    "    blog_post_url (str): The URL of the full blog post\n",
    "    \n",
    "    Returns:\n",
    "    str or None: The generated Threads post content, or None if generation fails\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"Create a short, engaging post for Threads (max 500 characters) about this scientific paper:\n",
    "    Title: {paper.title}\n",
    "    \n",
    "    Include a brief highlight and end with \"Read more: [URL]\"\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = openai.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates engaging social media posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=0.7\n",
    "        )\n",
    "        return f\"{response.choices[0].message.content.strip()} Read more: {blog_post_url}\"\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Threads post: {e}\")\n",
    "        return None\n",
    "\n",
    "def create_media_container(access_token, user_id, text):\n",
    "    \"\"\"\n",
    "    Creates a media container for a Threads post.\n",
    "    \n",
    "    Args:\n",
    "    access_token (str): Threads API access token\n",
    "    user_id (str): Threads user ID\n",
    "    text (str): Content of the post\n",
    "    \n",
    "    Returns:\n",
    "    dict: JSON response from the Threads API\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads\"\n",
    "    params = {\n",
    "        \"media_type\": \"TEXT\",\n",
    "        \"text\": text,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    response = requests.post(url, params=params)\n",
    "    print(f\"Create Media Container Status Code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "def publish_thread(access_token, user_id, creation_id):\n",
    "    \"\"\"\n",
    "    Publishes a thread on Threads.\n",
    "    \n",
    "    Args:\n",
    "    access_token (str): Threads API access token\n",
    "    user_id (str): Threads user ID\n",
    "    creation_id (str): ID of the media container to publish\n",
    "    \n",
    "    Returns:\n",
    "    dict: JSON response from the Threads API\n",
    "    \"\"\"\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads_publish\"\n",
    "    params = {\n",
    "        \"creation_id\": creation_id,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    response = requests.post(url, params=params)\n",
    "    print(f\"Publish Thread Status Code: {response.status_code}\")\n",
    "    return response.json()\n",
    "\n",
    "def post_to_threads(text):\n",
    "    \"\"\"\n",
    "    Posts content to Threads.\n",
    "    \n",
    "    Args:\n",
    "    text (str): Content to post\n",
    "    \n",
    "    Returns:\n",
    "    bool: True if posting was successful, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        container = create_media_container(THREADS_ACCESS_TOKEN, THREADS_USER_ID, text)\n",
    "        if 'id' in container:\n",
    "            print(\"Waiting 30 seconds before publishing...\")\n",
    "            time.sleep(30)\n",
    "            publish_result = publish_thread(THREADS_ACCESS_TOKEN, THREADS_USER_ID, container['id'])\n",
    "            if 'id' in publish_result:\n",
    "                print(\"Successfully posted to Threads!\")\n",
    "                return True\n",
    "        print(\"Failed to post to Threads.\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Error posting to Threads: {e}\")\n",
    "        return False\n",
    "\n",
    "def create_github_blog_post(title, content, date):\n",
    "    \"\"\"\n",
    "    Creates a new blog post on GitHub Pages.\n",
    "    \n",
    "    Args:\n",
    "    title (str): Title of the blog post\n",
    "    content (str): Content of the blog post\n",
    "    date (str): Date of the blog post in YYYY-MM-DD format\n",
    "    \n",
    "    Returns:\n",
    "    tuple: (bool, str) - Success status and URL of the created post\n",
    "    \"\"\"\n",
    "    file_name = f\"{date}-{title.lower().replace(' ', '-')[:50]}.md\"\n",
    "    file_content = f\"\"\"---\n",
    "layout: post\n",
    "title: \"{title}\"\n",
    "date: {date} {datetime.now().strftime('%H:%M:%S +0000')}\n",
    "categories: [blog, AI, research]\n",
    "---\n",
    "{content}\n",
    "\"\"\"\n",
    "    encoded_content = base64.b64encode(file_content.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/_posts/{file_name}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    # Check if file already exists\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Blog post already exists: {file_name}\")\n",
    "        return False, \"\"\n",
    "\n",
    "    # File doesn't exist, create new file\n",
    "    data = {\n",
    "        \"message\": f\"Add new blog post: {title}\",\n",
    "        \"content\": encoded_content\n",
    "    }\n",
    "\n",
    "    response = requests.put(url, headers=headers, json=data)\n",
    "    if response.status_code != 201:\n",
    "        print(f\"GitHub API Error: {response.status_code}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        return False, \"\"\n",
    "    \n",
    "    return True, f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{title.lower().replace(' ', '-')[:50]}\"\n",
    "\n",
    "def main():\n",
    "    \"\"\"\n",
    "    Main function to orchestrate the entire process:\n",
    "    1. Fetch the latest AI paper from arXiv\n",
    "    2. Generate a blog post summary\n",
    "    3. Create a GitHub Pages post\n",
    "    4. Share on Threads\n",
    "    \"\"\"\n",
    "    category = \"cs.AI\"  # Category for Artificial Intelligence\n",
    "    try:\n",
    "        # Fetch the latest paper\n",
    "        paper = fetch_latest_paper(category)\n",
    "        if not paper:\n",
    "            print(f\"No recent papers found in category: {category}\")\n",
    "            return\n",
    "\n",
    "        display(Markdown(f\"## Processing: {paper.title}\"))\n",
    "        \n",
    "        # Generate blog post\n",
    "        blog_post = generate_blog_post(paper)\n",
    "        if not blog_post:\n",
    "            print(f\"Failed to generate blog post for: {paper.title}\")\n",
    "            return\n",
    "\n",
    "        display(Markdown(f\"### Original Paper: [{paper.entry_id}]({paper.entry_id})\"))\n",
    "        display(Markdown(blog_post))\n",
    "        \n",
    "        # Save to GitHub\n",
    "        date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "        success, post_url = create_github_blog_post(paper.title, blog_post, date)\n",
    "        \n",
    "        if success:\n",
    "            print(f\"Successfully created blog post on GitHub: {post_url}\")\n",
    "        else:\n",
    "            print(\"Failed to create blog post on GitHub or post already exists.\")\n",
    "            # Generate a generic URL for existing posts\n",
    "            post_url = f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{paper.title.lower().replace(' ', '-')[:50]}\"\n",
    "\n",
    "        # Generate and post to Threads, regardless of GitHub success\n",
    "        threads_post = generate_threads_post(paper, post_url)\n",
    "        if threads_post:\n",
    "            display(Markdown(f\"### Threads Post:\\n{threads_post}\"))\n",
    "            if post_to_threads(threads_post):\n",
    "                print(\"Successfully posted to Threads!\")\n",
    "            else:\n",
    "                print(\"Failed to post to Threads.\")\n",
    "        else:\n",
    "            print(\"Failed to generate Threads post.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise  # This will display the full error traceback\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
