{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f7b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting automated blog creation process...\n",
      "üìù Configuration: 1 papers, 7 days back\n",
      "üîç Categories: cs.AI, cs.LG, cs.CL, cs.CV, stat.ML\n",
      "üìä Fetched 1 papers, 1 from last 7 days\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Processing: How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Original Paper: [http://arxiv.org/abs/2505.21505v1](http://arxiv.org/abs/2505.21505v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you fascinated by the inner workings of language processing in our brains? A new scientific paper titled \"How does Alignment Enhance LLMs' Multilingual Capabilities? A Language Neurons Perspective\" delves into the intricate mechanisms that underlie multilingual capabilities in Language Model Models (LLMs). Let's break down the key findings of this study in a way that is easy to understand.\n",
       "\n",
       "The researchers explored how aligning high-resource languages with low-resource languages can boost LLMs' ability to understand and generate text in multiple languages. They discovered that within the brains of these models, there are specialized neurons that are activated when processing different languages. These language-specific neurons play a crucial role in enabling LLMs to effectively navigate multilingual scenarios.\n",
       "\n",
       "By developing a sophisticated neuron identification algorithm, the researchers were able to categorize these neurons into language-specific, language-related, and language-agnostic types. This classification allowed them to dissect the internal processes involved in multilingual inference, which include multilingual understanding, shared semantic space reasoning, multilingual output space transformation, and vocabulary space outputting.\n",
       "\n",
       "One fascinating observation from the study was the phenomenon of \"Spontaneous Multilingual Alignment,\" where the models naturally adjust their alignment without explicit instructions. This natural ability to align languages could have significant implications for real-world applications, such as improving machine translation systems, language learning tools, and cross-cultural communication platforms.\n",
       "\n",
       "Understanding how LLMs leverage different types of neurons to enhance their multilingual capabilities provides valuable insights for researchers looking to advance the field of natural language processing. By studying the neural mechanisms involved in language processing, we can unravel the complexities of multilingual communication and develop more sophisticated AI systems that bridge linguistic barriers.\n",
       "\n",
       "In conclusion, this research sheds light on the intricate interplay between language-specific neurons and multilingual alignment in LLMs, offering a deeper understanding of how these models navigate diverse linguistic landscapes. The implications of this study extend beyond academia and into practical applications that could revolutionize how we interact with and understand languages in our increasingly globalized world."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DALL-E 3 image for: How does Alignment Enhance LLMs' Multilingual Capa...\n",
      "üé® Domain: natural language processing and text analysis\n",
      "‚úÖ DALL-E 3 image generated successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-7trcesexcJK1ksLDJeczoh3z/user-feQ9FVoAjxgjl56JZH3J4u5L/img-TWr0MtBZ526xUz8lESnGiNhV.png?st=2025-05-28T09%3A04%3A17Z&se=2025-05-28T11%3A04%3A17Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-27T23%3A03%3A48Z&ske=2025-05-28T23%3A03%3A48Z&sks=b&skv=2024-08-04&sig=FDMABfP2mOHGtfu%2BRK6AA/z6FmWzMuKPXsV5l2OoQEI%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image...\n",
      "üì§ Creating new file: assets/images/2025-05-28-95a4152d.png\n",
      "üì• Upload response: 201\n",
      "‚úÖ Image saved to GitHub: https://porkpy.github.io/research_blogger/assets/images/2025-05-28-95a4152d.png\n",
      "‚è≥ Waiting for GitHub Pages to deploy image (60 seconds)...\n",
      "‚úÖ GitHub Pages image is accessible!\n",
      "Successfully created blog post on GitHub: https://porkpy.github.io/research_blogger/2025/05/28/95a4152d/\n",
      "Waiting 30 seconds for link preview generation...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Threads Post:\n",
       "üß†üîó Dive into the fascinating world of language neurons! This study explores how alignment boosts multilingual capabilities in LLMs. Discover the brain's role in language processing and its potential impact on language learning. #neuroscience #multilingualism\n",
       "\n",
       "#AI #ArtificialIntelligence #MachineLearning #DataScience #Latest #Research #Arxiv #OpenAI\n",
       "\n",
       "Read more: https://porkpy.github.io/research_blogger/2025/05/28/95a4152d/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Media Container Status Code: 200\n",
      "Media container created with ID: 17867077875389393\n",
      "Waiting 30 seconds before publishing...\n",
      "Publish Thread Status Code: 200\n",
      "Successfully posted to Threads with ID: 18063894143281698\n",
      "Successfully posted to Threads with image!\n",
      "\n",
      "‚úÖ Processing complete! Created 1 new blog posts.\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import openai\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from IPython.display import display, Markdown, Image\n",
    "from requests.exceptions import RequestException\n",
    "from io import BytesIO\n",
    "\n",
    "# Import secrets from separate file (not committed to git)\n",
    "from secrets_config import (\n",
    "    OPENAI_API_KEY,\n",
    "    THREADS_USER_ID,\n",
    "    THREADS_ACCESS_TOKEN,\n",
    "    APP_SECRET,\n",
    "    GITHUB_TOKEN,\n",
    "    GITHUB_REPO,\n",
    "    GITHUB_PAGES_SITE,\n",
    "    FACEBOOK_ID,\n",
    "    INSTAGRAM_ACCESS_TOKEN\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# BLOG AUTOMATION CONFIGURATION - Modify these as needed\n",
    "# ============================================================================\n",
    "\n",
    "# arXiv paper settings\n",
    "ARXIV_CATEGORIES = [\"cs.AI\", \"cs.LG\", \"cs.CL\", \"cs.CV\", \"stat.ML\"]\n",
    "MAX_PAPERS_TO_PROCESS = 1       # Number of papers to fetch and potentially process\n",
    "DAYS_BACK_TO_SEARCH = 7         # How many days back to search for new papers\n",
    "\n",
    "# Content generation settings\n",
    "BLOG_POST_LENGTH = \"300-400\"    # Target word count for blog posts\n",
    "BLOG_POST_MAX_TOKENS = 500      # Max tokens for GPT response\n",
    "BLOG_POST_TEMPERATURE = 0.7     # Creativity level (0.0-1.0)\n",
    "\n",
    "# Threads post settings\n",
    "THREADS_MAX_CHARS = 350         # Max characters for main Threads text\n",
    "THREADS_HASHTAGS = \"#AI #ArtificialIntelligence #MachineLearning #DataScience #Latest #Research #Arxiv #OpenAI\"\n",
    "THREADS_WAIT_TIME = 30          # Seconds to wait before publishing\n",
    "THREADS_MAX_RETRIES = 3\n",
    "\n",
    "# Image generation settings (DALL-E 3)\n",
    "IMAGE_MODEL = \"dall-e-3\"        # \"dall-e-2\" or \"dall-e-3\"\n",
    "IMAGE_QUALITY = \"standard\"      # \"standard\" or \"hd\" (hd costs more)\n",
    "IMAGE_STYLE = \"natural\"         # \"natural\" or \"vivid\"\n",
    "IMAGE_SIZE = \"1024x1024\"        # \"1024x1024\", \"1792x1024\", or \"1024x1792\"\n",
    "\n",
    "# Processing settings\n",
    "SKIP_EXISTING_POSTS = True      # Skip papers that already have blog posts\n",
    "SAVE_IMAGES_TO_GITHUB = True    # Download and save images to prevent expiration\n",
    "LINK_PREVIEW_WAIT = 30          # Seconds to wait for link preview generation\n",
    "GITHUB_PAGES_IMAGE_WAIT = 60    # Seconds to wait for image deployment\n",
    "\n",
    "# Testing/debugging settings\n",
    "TEST_MODE = False               # Set to True to process only 1 paper for testing\n",
    "VERBOSE_OUTPUT = True           # Show detailed processing information\n",
    "\n",
    "# ============================================================================\n",
    "# Auto-adjust settings based on test mode\n",
    "# ============================================================================\n",
    "if TEST_MODE:\n",
    "    MAX_PAPERS_TO_PROCESS = 1\n",
    "    print(\"üß™ TEST MODE ENABLED - Processing only 1 paper\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_harvard_reference(paper):\n",
    "    authors = paper.authors\n",
    "    \n",
    "    if len(authors) == 1:\n",
    "        author_str = authors[0].name\n",
    "    elif len(authors) == 2:\n",
    "        author_str = f\"{authors[0].name} and {authors[1].name}\"\n",
    "    else:\n",
    "        author_str = f\"{authors[0].name} et al.\"\n",
    "    \n",
    "    year = paper.published.year\n",
    "    title = paper.title\n",
    "    \n",
    "    reference = f\"{author_str} ({year}) '{title}', arXiv preprint arXiv:{paper.get_short_id()}.\"\n",
    "    \n",
    "    return reference\n",
    "\n",
    "def fetch_latest_papers(categories=None, max_results=None, days_back=None):\n",
    "    # Use config defaults if no parameters provided\n",
    "    if categories is None:\n",
    "        categories = ARXIV_CATEGORIES\n",
    "    if max_results is None:\n",
    "        max_results = MAX_PAPERS_TO_PROCESS\n",
    "    if days_back is None:\n",
    "        days_back = DAYS_BACK_TO_SEARCH\n",
    "        \n",
    "    client_arxiv = arxiv.Client()  # Renamed to avoid confusion with OpenAI client\n",
    "    cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_back)\n",
    "    \n",
    "    category_query = \" OR \".join([f\"cat:{cat}\" for cat in categories])\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query = f\"({category_query})\",\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    results = list(client_arxiv.results(search))\n",
    "    recent_papers = [paper for paper in results if paper.published.replace(tzinfo=timezone.utc) > cutoff_date]\n",
    "    \n",
    "    if VERBOSE_OUTPUT:\n",
    "        print(f\"üìä Fetched {len(results)} papers, {len(recent_papers)} from last {days_back} days\")\n",
    "    \n",
    "    return recent_papers\n",
    "\n",
    "def generate_blog_post(paper):\n",
    "    authors = ', '.join([author.name for author in paper.authors])\n",
    "    prompt = f\"\"\"Write an engaging blog post about the following scientific paper:\n",
    "\n",
    "Title: {paper.title}\n",
    "Authors: {authors}\n",
    "Abstract: {paper.summary}\n",
    "\n",
    "The blog post should:\n",
    "1. Explain the main findings in simple terms\n",
    "2. Discuss potential real-world implications\n",
    "3. Be engaging and accessible to a general audience\n",
    "4. Be around {BLOG_POST_LENGTH} words long\n",
    "\n",
    "Blog Post:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes engaging blog posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=BLOG_POST_MAX_TOKENS,\n",
    "            temperature=BLOG_POST_TEMPERATURE\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating blog post: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_threads_post(paper, blog_post_url):\n",
    "    prompt = f\"\"\"Create a short, engaging post for Threads (max {THREADS_MAX_CHARS} characters) about this scientific paper:\n",
    "    Title: {paper.title}\n",
    "    \n",
    "    Include a brief highlight of the research and its potential impact. \n",
    "    Do not include any hashtags or 'Read more' statements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates engaging social media posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=BLOG_POST_TEMPERATURE\n",
    "        )\n",
    "        threads_text = response.choices[0].message.content.strip().replace(\":\", \"\")\n",
    "        \n",
    "        full_post = f\"{threads_text}\\n\\n{THREADS_HASHTAGS}\\n\\nRead more: {blog_post_url}\"\n",
    "        \n",
    "        if len(full_post) > 500:\n",
    "            available_chars = 500 - len(THREADS_HASHTAGS) - len(blog_post_url) - 15\n",
    "            truncated_text = threads_text[:available_chars-3] + \"...\"\n",
    "            full_post = f\"{truncated_text}\\n\\n{THREADS_HASHTAGS}\\n\\nRead more: {blog_post_url}\"\n",
    "        \n",
    "        return full_post\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Threads post: {e}\")\n",
    "        return None\n",
    "   \n",
    "def generate_ai_image(paper, threads_post):\n",
    "    \"\"\"\n",
    "    Generate an AI image using DALL-E 3 based on the research paper\n",
    "    \"\"\"\n",
    "    # Extract key concepts from both title and abstract for better understanding\n",
    "    title_words = paper.title.lower()\n",
    "    abstract_words = paper.summary.lower()\n",
    "    combined_text = f\"{title_words} {abstract_words}\"\n",
    "    \n",
    "    # Create a more detailed prompt based on the actual research content\n",
    "    # Look for specific technical terms and concepts\n",
    "    \n",
    "    visual_elements = []\n",
    "    domain_context = \"\"\n",
    "\n",
    "    domain_color_palettes = {\n",
    "        \"computer vision and image processing\": \"vibrant blues, greens, and digital highlights\",\n",
    "        \"natural language processing and text analysis\": \"warm oranges, soft whites, and typographic elements\",\n",
    "        \"machine learning and neural networks\": \"deep purples, electric blues, and gradient flows\",\n",
    "        \"robotics and autonomous systems\": \"industrial grays, precise reds, and mechanical details\",\n",
    "        \"data science and analytics\": \"analytical blues, data-point reds, and statistical patterns\",\n",
    "        \"medical AI and healthcare technology\": \"medical whites, diagnostic blues, and gentle healing greens\",\n",
    "        \"quantum computing and quantum information\": \"quantum blues, probability purples, and uncertainty patterns\",\n",
    "        \"reinforcement learning and intelligent agents\": \"reward golds, strategic blues, and environmental greens\",\n",
    "        \"artificial intelligence research\": \"technological blues, innovative purples, and conceptual gradients\"\n",
    "    }\n",
    "    \n",
    "    # Computer Vision / Image Processing\n",
    "    if any(word in combined_text for word in ['image', 'vision', 'visual', 'detection', 'segmentation', 'object', 'face', 'recognition']):\n",
    "        domain_context = \"computer vision and image processing\"\n",
    "        visual_elements.extend([\n",
    "            \"digital image grids with highlighted features\",\n",
    "            \"geometric detection boxes and annotations\",\n",
    "            \"layered visual processing pipelines\",\n",
    "            \"camera or sensor imagery with analytical overlays\"\n",
    "        ])\n",
    "    \n",
    "    # Natural Language Processing\n",
    "    elif any(word in combined_text for word in ['language', 'text', 'nlp', 'translation', 'sentiment', 'dialogue', 'conversation', 'llm']):\n",
    "        domain_context = \"natural language processing and text analysis\"\n",
    "        visual_elements.extend([\n",
    "            \"flowing text streams transforming between languages\",\n",
    "            \"word clouds with connecting semantic relationships\",\n",
    "            \"chat bubbles and conversation interfaces\",\n",
    "            \"linguistic trees and grammar structures\"\n",
    "        ])\n",
    "    \n",
    "    # Machine Learning / Neural Networks\n",
    "    elif any(word in combined_text for word in ['neural', 'network', 'learning', 'training', 'model', 'algorithm', 'optimization']):\n",
    "        domain_context = \"machine learning and neural networks\"\n",
    "        visual_elements.extend([\n",
    "            \"interconnected neural network nodes with flowing data\",\n",
    "            \"gradient flows and optimization landscapes\",\n",
    "            \"training data points clustering and separating\",\n",
    "            \"layered network architectures with information flow\"\n",
    "        ])\n",
    "    \n",
    "    # Robotics / Autonomous Systems\n",
    "    elif any(word in combined_text for word in ['robot', 'autonomous', 'control', 'manipulation', 'navigation', 'motion']):\n",
    "        domain_context = \"robotics and autonomous systems\"\n",
    "        visual_elements.extend([\n",
    "            \"robotic arms with precise movement trajectories\",\n",
    "            \"autonomous vehicles navigating environments\",\n",
    "            \"sensor data visualization around robotic systems\",\n",
    "            \"mechanical components with motion indicators\"\n",
    "        ])\n",
    "    \n",
    "    # Data Science / Analysis\n",
    "    elif any(word in combined_text for word in ['data', 'analysis', 'mining', 'clustering', 'classification', 'prediction', 'statistics']):\n",
    "        domain_context = \"data science and analytics\"\n",
    "        visual_elements.extend([\n",
    "            \"data visualization charts and graphs\",\n",
    "            \"clustering patterns and data point relationships\",\n",
    "            \"statistical distributions and trend lines\",\n",
    "            \"database connections and information flow diagrams\"\n",
    "        ])\n",
    "    \n",
    "    # Healthcare / Medical AI\n",
    "    elif any(word in combined_text for word in ['medical', 'health', 'diagnosis', 'patient', 'clinical', 'drug', 'disease']):\n",
    "        domain_context = \"medical AI and healthcare technology\"\n",
    "        visual_elements.extend([\n",
    "            \"medical scan imagery with AI analysis highlights\",\n",
    "            \"molecular structures and drug interactions\",\n",
    "            \"patient data flows and diagnostic pathways\",\n",
    "            \"healthcare monitoring interfaces and vital signs\"\n",
    "        ])\n",
    "    \n",
    "    # Quantum Computing\n",
    "    elif any(word in combined_text for word in ['quantum', 'qubit', 'entanglement', 'superposition']):\n",
    "        domain_context = \"quantum computing and quantum information\"\n",
    "        visual_elements.extend([\n",
    "            \"quantum state visualizations with wave functions\",\n",
    "            \"entangled particle representations\",\n",
    "            \"quantum circuit diagrams with gate operations\",\n",
    "            \"probabilistic quantum measurement outcomes\"\n",
    "        ])\n",
    "    \n",
    "    # Reinforcement Learning / Gaming\n",
    "    elif any(word in combined_text for word in ['reinforcement', 'reward', 'policy', 'agent', 'environment', 'game']):\n",
    "        domain_context = \"reinforcement learning and intelligent agents\"\n",
    "        visual_elements.extend([\n",
    "            \"agent-environment interaction loops\",\n",
    "            \"reward signal visualizations and policy maps\",\n",
    "            \"decision trees and action space exploration\",\n",
    "            \"learning progress and performance curves\"\n",
    "        ])\n",
    "    \n",
    "    # Default AI Research\n",
    "    else:\n",
    "        domain_context = \"artificial intelligence research\"\n",
    "        visual_elements.extend([\n",
    "            \"abstract AI concept representations\",\n",
    "            \"algorithmic flow diagrams\",\n",
    "            \"digital transformation processes\",\n",
    "            \"computational thinking visualizations\"\n",
    "        ])\n",
    "    \n",
    "    # Extract specific paper concepts to make it even more targeted\n",
    "    specific_concepts = []\n",
    "    \n",
    "    # Look for specific techniques or models mentioned\n",
    "    techniques = ['transformer', 'cnn', 'rnn', 'lstm', 'bert', 'gpt', 'diffusion', 'gan', 'vae', 'attention']\n",
    "    for tech in techniques:\n",
    "        if tech in combined_text:\n",
    "            specific_concepts.append(tech)\n",
    "    \n",
    "    # Look for application domains\n",
    "    applications = ['autonomous driving', 'medical imaging', 'speech recognition', 'recommendation', 'translation']\n",
    "    for app in applications:\n",
    "        if app.replace(' ', '') in combined_text.replace(' ', ''):\n",
    "            specific_concepts.append(app)\n",
    "    \n",
    "    # Create the enhanced prompt\n",
    "    base_elements = \", \".join(visual_elements[:2])  # Use first 2 visual elements\n",
    "    \n",
    "    concept_addition = \"\"\n",
    "    if specific_concepts:\n",
    "        concept_addition = f\", specifically highlighting {specific_concepts[0]} concepts\"\n",
    "    \n",
    "    # Extract a key insight from the title for visual focus\n",
    "    title_focus = \"\"\n",
    "    if any(word in title_words for word in ['novel', 'new', 'improved', 'efficient', 'robust']):\n",
    "        title_focus = \" showcasing innovation and advancement\"\n",
    "    elif any(word in title_words for word in ['multi', 'cross', 'joint', 'unified']):\n",
    "        title_focus = \" emphasizing integration and connectivity\"\n",
    "    elif any(word in title_words for word in ['real-time', 'fast', 'rapid', 'efficient']):\n",
    "        title_focus = \" conveying speed and efficiency\"\n",
    "    \n",
    "    # Get the domain-specific color palette\n",
    "    color_palette = domain_color_palettes.get(domain_context, \"modern professional colors with subtle gradients\")\n",
    "    \n",
    "    prompt = f\"\"\"\n",
    "    Create a modern, sophisticated illustration representing {domain_context}. \n",
    "    The image should feature {base_elements}{concept_addition}{title_focus}.\n",
    "    \n",
    "    Use a palette of {color_palette}. \n",
    "    The style should be clean, minimalist, and technically accurate, suitable for \n",
    "    a research publication or technical blog. \n",
    "    \n",
    "    Avoid any text, human figures, or company logos. Show concrete, recognizable \n",
    "    technical elements and concepts that directly relate to {domain_context.split(' ')[0]} \n",
    "    research. Make the connection to the research topic immediately clear and visually \n",
    "    representative of the actual work being done.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Generating DALL-E 3 image for: {paper.title[:50]}...\")\n",
    "        print(f\"üé® Domain: {domain_context}\")\n",
    "        if specific_concepts:\n",
    "            print(f\"üîç Concepts: {', '.join(specific_concepts[:2])}\")\n",
    "        \n",
    "        response = client.images.generate(\n",
    "            model=IMAGE_MODEL,\n",
    "            prompt=prompt,\n",
    "            n=1,\n",
    "            size=IMAGE_SIZE,\n",
    "            quality=IMAGE_QUALITY,\n",
    "            style=IMAGE_STYLE\n",
    "        )\n",
    "        \n",
    "        image_url = response.data[0].url\n",
    "        print(\"‚úÖ DALL-E 3 image generated successfully!\")\n",
    "        \n",
    "        # Display the image in the notebook (if running in Jupyter)\n",
    "        try:\n",
    "            from IPython.display import display, Image\n",
    "            display(Image(url=image_url))\n",
    "        except ImportError:\n",
    "            print(f\"Image URL: {image_url}\")\n",
    "        \n",
    "        return image_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating DALL-E 3 image: {e}\")\n",
    "        \n",
    "        # Fallback: try with a simpler but still specific prompt\n",
    "        try:\n",
    "            print(\"Trying with simplified prompt...\")\n",
    "            simple_prompt = f\"A clean, modern illustration of {domain_context}, minimalist style, blue and purple gradient, technical diagram aesthetic\"\n",
    "            \n",
    "            response = client.images.generate(\n",
    "                model=IMAGE_MODEL,\n",
    "                prompt=simple_prompt,\n",
    "                n=1,\n",
    "                size=IMAGE_SIZE,\n",
    "                quality=IMAGE_QUALITY\n",
    "            )\n",
    "            \n",
    "            image_url = response.data[0].url\n",
    "            print(\"‚úÖ Fallback image generated successfully!\")\n",
    "            return image_url\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Fallback also failed: {e2}\")\n",
    "            return None\n",
    "\n",
    "def download_and_save_image(image_url, paper_short_id, date):\n",
    "    \"\"\"\n",
    "    Download the AI image and save it to GitHub repository\n",
    "    This prevents the image from expiring\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import base64\n",
    "    \n",
    "    try:\n",
    "        # Download the image\n",
    "        print(\"Downloading image...\")\n",
    "        img_response = requests.get(image_url)\n",
    "        img_response.raise_for_status()\n",
    "        \n",
    "        # Create filename\n",
    "        image_filename = f\"assets/images/{date}-{paper_short_id}.png\"\n",
    "        \n",
    "        # Encode image for GitHub API\n",
    "        encoded_image = base64.b64encode(img_response.content).decode(\"utf-8\")\n",
    "        \n",
    "        # Upload to GitHub\n",
    "        url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{image_filename}\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"X-GitHub-Api-Version\": \"2022-11-28\"  # Use the API version from docs\n",
    "        }\n",
    "        \n",
    "        # Always try to create as new file first (no sha parameter)\n",
    "        print(f\"üì§ Creating new file: {image_filename}\")\n",
    "        data = {\n",
    "            \"message\": f\"Add image for blog post {paper_short_id}\",\n",
    "            \"content\": encoded_image\n",
    "        }\n",
    "        \n",
    "        response = requests.put(url, headers=headers, json=data)\n",
    "        print(f\"üì• Upload response: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            # Successfully created new file\n",
    "            github_image_url = f\"https://{GITHUB_PAGES_SITE}/{image_filename}\"\n",
    "            print(f\"‚úÖ Image saved to GitHub: {github_image_url}\")\n",
    "            \n",
    "            # Wait for GitHub Pages to deploy the image\n",
    "            print(f\"‚è≥ Waiting for GitHub Pages to deploy image ({GITHUB_PAGES_IMAGE_WAIT} seconds)...\")\n",
    "            time.sleep(GITHUB_PAGES_IMAGE_WAIT)\n",
    "            \n",
    "            # Test if the image is accessible\n",
    "            try:\n",
    "                test_response = requests.head(github_image_url, timeout=10)\n",
    "                if test_response.status_code == 200:\n",
    "                    print(\"‚úÖ GitHub Pages image is accessible!\")\n",
    "                    return github_image_url\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è GitHub Pages image not ready (status: {test_response.status_code})\")\n",
    "                    print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                    return image_url\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Cannot verify GitHub Pages image accessibility: {e}\")\n",
    "                print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                return image_url\n",
    "                \n",
    "        elif response.status_code == 422:\n",
    "            # File might already exist, try to update it\n",
    "            print(\"üîÑ File might exist, checking and updating...\")\n",
    "            \n",
    "            # Get the existing file info\n",
    "            check_response = requests.get(url, headers=headers)\n",
    "            if check_response.status_code == 200:\n",
    "                file_info = check_response.json()\n",
    "                print(f\"üìÑ File exists, updating with sha: {file_info['sha'][:8]}...\")\n",
    "                \n",
    "                # Update with sha\n",
    "                update_data = {\n",
    "                    \"message\": f\"Update image for blog post {paper_short_id}\",\n",
    "                    \"content\": encoded_image,\n",
    "                    \"sha\": file_info[\"sha\"]\n",
    "                }\n",
    "                \n",
    "                update_response = requests.put(url, headers=headers, json=update_data)\n",
    "                if update_response.status_code == 200:\n",
    "                    github_image_url = f\"https://{GITHUB_PAGES_SITE}/{image_filename}\"\n",
    "                    print(f\"‚úÖ Image updated on GitHub: {github_image_url}\")\n",
    "                    return github_image_url\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed to update: {update_response.status_code}\")\n",
    "                    print(f\"Response: {update_response.text}\")\n",
    "                    return image_url\n",
    "            else:\n",
    "                print(f\"‚ùå Cannot check file existence: {check_response.status_code}\")\n",
    "                print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                return image_url\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to save image to GitHub: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            print(\"üìé Using original OpenAI URL as fallback\")\n",
    "            return image_url\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving image: {e}\")\n",
    "        print(\"üìé Using original OpenAI URL as fallback\")\n",
    "        return image_url\n",
    "\n",
    "def create_github_blog_post(paper, content, date, short_id, image_url):\n",
    "    # Use consistent short_id for the file name\n",
    "    file_name = f\"{date}-{short_id}.md\"\n",
    "    \n",
    "    # Generate Harvard reference\n",
    "    harvard_reference = generate_harvard_reference(paper)\n",
    "    \n",
    "    # Fixed: No indentation in front matter\n",
    "    file_content = f\"\"\"---\n",
    "layout: post\n",
    "title: \"{paper.title}\"\n",
    "date: {date} {datetime.now().strftime('%H:%M:%S +0000')}\n",
    "categories: [blog, AI, research]\n",
    "image: {image_url}\n",
    "---\n",
    "![AI Generated Image]({image_url})\n",
    "\n",
    "{content}\n",
    "\n",
    "## Original Research Paper\n",
    "For more details, please refer to the original research paper:\n",
    "[{paper.title}]({paper.entry_id})\n",
    "\n",
    "## Reference\n",
    "{harvard_reference}\n",
    "\"\"\"\n",
    "    \n",
    "    encoded_content = base64.b64encode(file_content.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/_posts/{file_name}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    # Check if file already exists\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Blog post already exists: {file_name}\")\n",
    "        return False, \"\"\n",
    "\n",
    "    # File doesn't exist, create new file\n",
    "    data = {\n",
    "        \"message\": f\"Add new blog post: {paper.title}\",\n",
    "        \"content\": encoded_content\n",
    "    }\n",
    "\n",
    "    response = requests.put(url, headers=headers, json=data)\n",
    "    if response.status_code != 201:\n",
    "        print(f\"GitHub API Error: {response.status_code}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        return False, \"\"\n",
    "    \n",
    "    # Construct the URL based on the file name\n",
    "    post_url = f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{short_id}/\"\n",
    "    return True, post_url\n",
    "   \n",
    "\n",
    "def check_existing_post(short_id, date):\n",
    "    file_name = f\"{date}-{short_id}.md\"\n",
    "    url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/_posts/{file_name}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.status_code == 200\n",
    "\n",
    "def create_media_container(access_token, user_id, text, image_url):\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads\"\n",
    "    \n",
    "    params = {\n",
    "        \"media_type\": \"IMAGE\",\n",
    "        \"image_url\": image_url,\n",
    "        \"text\": text,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Create Media Container Status Code: {response.status_code}\")\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error creating media container: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Response content: {e.response.text}\")\n",
    "        return None\n",
    "\n",
    "def publish_thread(access_token, user_id, creation_id):\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads_publish\"\n",
    "    \n",
    "    params = {\n",
    "        \"creation_id\": creation_id,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Publish Thread Status Code: {response.status_code}\")\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error publishing thread: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Response content: {e.response.text}\")\n",
    "        return None\n",
    "\n",
    "def post_to_threads(text, image_url, access_token, user_id, initial_wait=30, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Step 1: Create media container\n",
    "            container = create_media_container(access_token, user_id, text, image_url)\n",
    "            if container is None or 'id' not in container:\n",
    "                print(\"Failed to create media container.\")\n",
    "                return False\n",
    "\n",
    "            container_id = container['id']\n",
    "            print(f\"Media container created with ID: {container_id}\")\n",
    "\n",
    "            # Wait before publishing\n",
    "            print(f\"Waiting {initial_wait} seconds before publishing...\")\n",
    "            time.sleep(initial_wait)\n",
    "\n",
    "            # Step 2: Publish the thread\n",
    "            publish_result = publish_thread(access_token, user_id, container_id)\n",
    "            if publish_result is None or 'id' not in publish_result:\n",
    "                print(\"Failed to publish thread.\")\n",
    "                return False\n",
    "\n",
    "            print(f\"Successfully posted to Threads with ID: {publish_result['id']}\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error posting to Threads: {e}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {initial_wait} seconds...\")\n",
    "                time.sleep(initial_wait)\n",
    "            else:\n",
    "                print(\"Max retries reached. Failed to post to Threads.\")\n",
    "                return False\n",
    "\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        if VERBOSE_OUTPUT:\n",
    "            print(\"üöÄ Starting automated blog creation process...\")\n",
    "            print(f\"üìù Configuration: {MAX_PAPERS_TO_PROCESS} papers, {DAYS_BACK_TO_SEARCH} days back\")\n",
    "            print(f\"üîç Categories: {', '.join(ARXIV_CATEGORIES)}\")\n",
    "        \n",
    "        papers = fetch_latest_papers()\n",
    "        if not papers:\n",
    "            print(f\"No recent papers found in categories: {ARXIV_CATEGORIES}\")\n",
    "            return\n",
    "\n",
    "        processed_count = 0\n",
    "        for paper in papers:\n",
    "            display(Markdown(f\"## Processing: {paper.title}\"))\n",
    "            \n",
    "            short_id = hashlib.md5(paper.title.encode()).hexdigest()[:8]\n",
    "            \n",
    "            date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            if SKIP_EXISTING_POSTS and check_existing_post(short_id, date):\n",
    "                print(f\"Blog post already exists for: {paper.title}\")\n",
    "                print(\"Skipping to next paper...\")\n",
    "                continue\n",
    "\n",
    "            blog_post = generate_blog_post(paper)\n",
    "            if not blog_post:\n",
    "                print(f\"Failed to generate blog post for: {paper.title}\")\n",
    "                print(\"Skipping to next paper...\")\n",
    "                continue\n",
    "\n",
    "            display(Markdown(f\"### Original Paper: [{paper.entry_id}]({paper.entry_id})\"))\n",
    "            display(Markdown(blog_post))\n",
    "            \n",
    "            # Generate a temporary post URL\n",
    "            temp_post_url = f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{short_id}/\"\n",
    "            \n",
    "            # Generate Threads post first\n",
    "            threads_post = generate_threads_post(paper, temp_post_url)\n",
    "            if not threads_post:\n",
    "                print(\"Failed to generate Threads post. Skipping to next paper...\")\n",
    "                continue\n",
    "            \n",
    "            # Generate image based on paper content\n",
    "            image_url = generate_ai_image(paper, threads_post)\n",
    "            if not image_url:\n",
    "                print(\"Failed to generate AI image. Skipping to next paper...\")\n",
    "                continue\n",
    "            \n",
    "            # Download and save the image to prevent expiration\n",
    "            if SAVE_IMAGES_TO_GITHUB:\n",
    "                image_url = download_and_save_image(image_url, short_id, date)\n",
    "            \n",
    "            # Create GitHub blog post with the generated image\n",
    "            success, post_url = create_github_blog_post(paper, blog_post, date, short_id, image_url)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"Successfully created blog post on GitHub: {post_url}\")\n",
    "                \n",
    "                # Add delay to allow for link preview generation\n",
    "                print(f\"Waiting {LINK_PREVIEW_WAIT} seconds for link preview generation...\")\n",
    "                time.sleep(LINK_PREVIEW_WAIT)\n",
    "                \n",
    "                # Update the Threads post with the correct URL if it changed\n",
    "                if post_url != temp_post_url:\n",
    "                    threads_post = threads_post.replace(temp_post_url, post_url)\n",
    "                \n",
    "                display(Markdown(f\"### Threads Post:\\n{threads_post}\"))\n",
    "                if post_to_threads(threads_post, image_url, THREADS_ACCESS_TOKEN, THREADS_USER_ID, THREADS_WAIT_TIME, THREADS_MAX_RETRIES):\n",
    "                    print(\"Successfully posted to Threads with image!\")\n",
    "                else:\n",
    "                    print(\"Failed to post to Threads.\")\n",
    "                \n",
    "                processed_count += 1\n",
    "            else:\n",
    "                print(\"Failed to create blog post on GitHub.\")\n",
    "        \n",
    "        if VERBOSE_OUTPUT:\n",
    "            print(f\"\\n‚úÖ Processing complete! Created {processed_count} new blog posts.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
