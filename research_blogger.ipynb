{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241f7b73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ Starting automated blog creation process...\n",
      "üìù Configuration: 3 papers, 7 days back\n",
      "üîç Categories: cs.AI, cs.LG, cs.CL, cs.CV, stat.ML\n",
      "üìä Fetched 3 papers, 3 from last 7 days\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Processing: HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blog post already exists for: HunyuanVideo-Avatar: High-Fidelity Audio-Driven Human Animation for Multiple Characters\n",
      "Skipping to next paper...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Processing: Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Original Paper: [http://arxiv.org/abs/2505.20155v1](http://arxiv.org/abs/2505.20155v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you ready to witness the cutting-edge advancements in large language models (LLMs) that are set to revolutionize the world of artificial intelligence? A recent scientific paper titled \"Pangu Light: Weight Re-Initialization for Pruning and Accelerating LLMs\" by a team of brilliant researchers has unveiled a groundbreaking framework that could potentially reshape the landscape of model compression and acceleration.\n",
       "\n",
       "So, what does all this scientific jargon actually mean for us non-experts? Let's break it down. Large language models like GPT-3 have been hailed for their remarkable capabilities in natural language processing tasks, but their sheer size and computational demands have posed significant challenges for practical use. The researchers behind Pangu Light recognized the potential of structured pruning, a technique that selectively removes unnecessary parameters from the model to reduce its size and speed up inference. However, existing pruning methods have often led to performance degradation due to aggressive reductions in model width and depth.\n",
       "\n",
       "Enter Pangu Light, a game-changing framework that not only prunes LLMs but also strategically re-initializes and adjusts the remaining weights to improve the model's training accuracy post-pruning. By introducing innovative techniques like Cross-Layer Attention Pruning and Stabilized LayerNorm Pruning, Pangu Light ensures that the pruned model starts off on the right foot, mitigating performance drops and enhancing efficiency.\n",
       "\n",
       "But why should we care about all this technical wizardry? The implications are far-reaching. Imagine faster and more accurate language models that can power a wide range of applications, from chatbots and virtual assistants to language translation services and content generation tools. By optimizing the trade-off between accuracy and efficiency, Pangu Light opens up new possibilities for deploying sophisticated AI models in real-world scenarios with improved performance.\n",
       "\n",
       "In a world where AI is becoming increasingly intertwined with our daily lives, innovations like Pangu Light have the potential to accelerate the development and deployment of advanced language technologies. With superior accuracy and efficiency, Pangu Light could pave the way for more accessible and powerful AI applications that benefit society as a whole.\n",
       "\n",
       "So, the next time you interact with a language model online or use a virtual assistant, remember the behind-the-scenes work of researchers like Hanting Chen and Yunhe Wang, whose work on Pangu Light is shaping the future of AI in tangible and impactful ways. Exciting times lie ahead as we witness the evolution of intelligent systems that are not just smarter but also faster and more efficient than ever before."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DALL-E 3 image for: Pangu Light: Weight Re-Initialization for Pruning ...\n",
      "‚úÖ DALL-E 3 image generated successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-7trcesexcJK1ksLDJeczoh3z/user-feQ9FVoAjxgjl56JZH3J4u5L/img-pj4hkzq5yB7Va6BTovnGXzoB.png?st=2025-05-27T20%3A56%3A09Z&se=2025-05-27T22%3A56%3A09Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-27T21%3A56%3A09Z&ske=2025-05-28T21%3A56%3A09Z&sks=b&skv=2024-08-04&sig=YJszLGKgtEV6eEQlon5DCEjjyQgQa4tAXiwSz3cZfl4%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image...\n",
      "‚ùå Failed to save image to GitHub: 422\n",
      "Response: {\"message\":\"Invalid request.\\n\\n\\\"sha\\\" wasn't supplied.\",\"documentation_url\":\"https://docs.github.com/rest/repos/contents#create-or-update-file-contents\",\"status\":\"422\"}\n",
      "Successfully created blog post on GitHub: https://porkpy.github.io/research_blogger/2025/05/27/ddef2e34/\n",
      "Waiting 30 seconds for link preview generation...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Threads Post:\n",
       "üåü New research alert! üìö Scientists have developed Pangu Light, a method that improves the efficiency of Large Language Models (LLMs) by re-initializing weight values during pruning. This innovative approach could lead to significant advancements in accelerating LLMs, revolutionizing natural language processing! üöÄüî¨ #ScienceTwitte...\n",
       "\n",
       "#AI #ArtificialIntelligence #MachineLearning #DataScience #Latest #Research #Arxiv #OpenAI\n",
       "\n",
       "Read more: https://porkpy.github.io/research_blogger/2025/05/27/ddef2e34/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Media Container Status Code: 200\n",
      "Media container created with ID: 18342774799082977\n",
      "Waiting 30 seconds before publishing...\n",
      "Publish Thread Status Code: 200\n",
      "Successfully posted to Threads with ID: 17971025606889882\n",
      "Successfully posted to Threads with image!\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "## Processing: UORA: Uniform Orthogonal Reinitialization Adaptation in Parameter-Efficient Fine-Tuning of Large Models"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Original Paper: [http://arxiv.org/abs/2505.20154v1](http://arxiv.org/abs/2505.20154v1)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "Are you ready to revolutionize the way large language models are fine-tuned? A groundbreaking new study by Zhang et al. introduces a game-changing approach called UORA (Uniform Orthogonal Reinitialization Adaptation) that could transform the efficiency of parameter tuning in large models.\n",
       "\n",
       "So, what exactly is UORA and why should we be excited about it? In simple terms, UORA is like a magic wand for fine-tuning large language models. It works by strategically reinitializing certain parts of the model to make it more efficient, without sacrificing performance. Imagine being able to fine-tune your model with fewer parameters, saving time and computational resources, while still achieving top-notch results. That's the power of UORA.\n",
       "\n",
       "But why should we care about this in the real world? Well, imagine a scenario where companies or researchers are training massive language models for various applications like natural language processing or image classification. These models require a huge number of parameters, which can be computationally expensive and time-consuming to fine-tune. With UORA, this process becomes much more efficient, making it easier and more cost-effective to adapt these models to specific tasks or datasets.\n",
       "\n",
       "Think about the impact this could have on industries like healthcare, finance, or even social media. Faster and more resource-efficient fine-tuning means quicker deployment of advanced AI models for tasks like medical diagnosis, fraud detection, or content moderation. This could lead to improved accuracy, faster decision-making, and ultimately, better outcomes for businesses and society as a whole.\n",
       "\n",
       "In a world where data is king and AI models reign supreme, innovations like UORA pave the way for more scalable and sustainable AI development. By reducing the computational overhead of fine-tuning large models, researchers and practitioners can focus on pushing the boundaries of AI technology without breaking the bank.\n",
       "\n",
       "So, the next time you hear about cutting-edge AI applications or groundbreaking research in natural language processing, remember the unsung hero behind the scenes ‚Äì UORA, the key to unlocking the full potential of large language models. The future of AI just got a whole lot brighter, thanks to UORA's parameter-efficient fine-tuning approach."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating DALL-E 3 image for: UORA: Uniform Orthogonal Reinitialization Adaptati...\n",
      "‚úÖ DALL-E 3 image generated successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<img src=\"https://oaidalleapiprodscus.blob.core.windows.net/private/org-7trcesexcJK1ksLDJeczoh3z/user-feQ9FVoAjxgjl56JZH3J4u5L/img-8GuEMb3g8pPyvDlUAKZElmQL.png?st=2025-05-27T20%3A57%3A55Z&se=2025-05-27T22%3A57%3A55Z&sp=r&sv=2024-08-04&sr=b&rscd=inline&rsct=image/png&skoid=52f8f7b3-ca8d-4b21-9807-8b9df114d84c&sktid=a48cca56-e6da-484e-a814-9c849652bcb3&skt=2025-05-27T15%3A48%3A18Z&ske=2025-05-28T15%3A48%3A18Z&sks=b&skv=2024-08-04&sig=DNZpeEhmtcV6zy0W%2B8A%2BGUfk/xTD%2BZGT/ZW9xZkImXI%3D\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading image...\n",
      "‚ùå Failed to save image to GitHub: 422\n",
      "Response: {\"message\":\"Invalid request.\\n\\n\\\"sha\\\" wasn't supplied.\",\"documentation_url\":\"https://docs.github.com/rest/repos/contents#create-or-update-file-contents\",\"status\":\"422\"}\n",
      "Successfully created blog post on GitHub: https://porkpy.github.io/research_blogger/2025/05/27/6ff727f2/\n",
      "Waiting 30 seconds for link preview generation...\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "### Threads Post:\n",
       "üß† Just In A groundbreaking study introduces UORA, a novel technique for efficient fine-tuning of large models. By utilizing Uniform Orthogonal Reinitialization Adaptation, this method could revolutionize model optimization in AI research. üåü #AI #Research #Innovation\n",
       "\n",
       "#AI #ArtificialIntelligence #MachineLearning #DataScience #Latest #Research #Arxiv #OpenAI\n",
       "\n",
       "Read more: https://porkpy.github.io/research_blogger/2025/05/27/6ff727f2/"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create Media Container Status Code: 200\n",
      "Media container created with ID: 18051357026590187\n",
      "Waiting 30 seconds before publishing...\n",
      "Publish Thread Status Code: 200\n",
      "Successfully posted to Threads with ID: 18045347765575029\n",
      "Successfully posted to Threads with image!\n",
      "\n",
      "‚úÖ Processing complete! Created 2 new blog posts.\n"
     ]
    }
   ],
   "source": [
    "import arxiv\n",
    "import openai\n",
    "import requests\n",
    "import base64\n",
    "import time\n",
    "import hashlib\n",
    "import json\n",
    "from datetime import datetime, timedelta, timezone\n",
    "from IPython.display import display, Markdown, Image\n",
    "from requests.exceptions import RequestException\n",
    "from io import BytesIO\n",
    "\n",
    "# Import secrets from separate file (not committed to git)\n",
    "from secrets_config import (\n",
    "    OPENAI_API_KEY,\n",
    "    THREADS_USER_ID,\n",
    "    THREADS_ACCESS_TOKEN,\n",
    "    APP_SECRET,\n",
    "    GITHUB_TOKEN,\n",
    "    GITHUB_REPO,\n",
    "    GITHUB_PAGES_SITE,\n",
    "    FACEBOOK_ID,\n",
    "    INSTAGRAM_ACCESS_TOKEN\n",
    ")\n",
    "\n",
    "# ============================================================================\n",
    "# BLOG AUTOMATION CONFIGURATION - Modify these as needed\n",
    "# ============================================================================\n",
    "\n",
    "# arXiv paper settings\n",
    "ARXIV_CATEGORIES = [\"cs.AI\", \"cs.LG\", \"cs.CL\", \"cs.CV\", \"stat.ML\"]\n",
    "MAX_PAPERS_TO_PROCESS = 5       # Number of papers to fetch and potentially process\n",
    "DAYS_BACK_TO_SEARCH = 7         # How many days back to search for new papers\n",
    "\n",
    "# Content generation settings\n",
    "BLOG_POST_LENGTH = \"300-400\"    # Target word count for blog posts\n",
    "BLOG_POST_MAX_TOKENS = 500      # Max tokens for GPT response\n",
    "BLOG_POST_TEMPERATURE = 0.7     # Creativity level (0.0-1.0)\n",
    "\n",
    "# Threads post settings\n",
    "THREADS_MAX_CHARS = 350         # Max characters for main Threads text\n",
    "THREADS_HASHTAGS = \"#AI #ArtificialIntelligence #MachineLearning #DataScience #Latest #Research #Arxiv #OpenAI\"\n",
    "THREADS_WAIT_TIME = 30          # Seconds to wait before publishing\n",
    "THREADS_MAX_RETRIES = 3\n",
    "\n",
    "# Image generation settings (DALL-E 3)\n",
    "IMAGE_MODEL = \"dall-e-3\"        # \"dall-e-2\" or \"dall-e-3\"\n",
    "IMAGE_QUALITY = \"standard\"      # \"standard\" or \"hd\" (hd costs more)\n",
    "IMAGE_STYLE = \"natural\"         # \"natural\" or \"vivid\"\n",
    "IMAGE_SIZE = \"1024x1024\"        # \"1024x1024\", \"1792x1024\", or \"1024x1792\"\n",
    "\n",
    "# Processing settings\n",
    "SKIP_EXISTING_POSTS = True      # Skip papers that already have blog posts\n",
    "SAVE_IMAGES_TO_GITHUB = True    # Download and save images to prevent expiration\n",
    "LINK_PREVIEW_WAIT = 30          # Seconds to wait for link preview generation\n",
    "GITHUB_PAGES_IMAGE_WAIT = 60    # Seconds to wait for image deployment\n",
    "\n",
    "# Testing/debugging settings\n",
    "TEST_MODE = False               # Set to True to process only 1 paper for testing\n",
    "VERBOSE_OUTPUT = True           # Show detailed processing information\n",
    "\n",
    "# ============================================================================\n",
    "# Auto-adjust settings based on test mode\n",
    "# ============================================================================\n",
    "if TEST_MODE:\n",
    "    MAX_PAPERS_TO_PROCESS = 1\n",
    "    print(\"üß™ TEST MODE ENABLED - Processing only 1 paper\")\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = openai.OpenAI(api_key=OPENAI_API_KEY)\n",
    "\n",
    "# ============================================================================\n",
    "# FUNCTIONS\n",
    "# ============================================================================\n",
    "\n",
    "def generate_harvard_reference(paper):\n",
    "    authors = paper.authors\n",
    "    \n",
    "    if len(authors) == 1:\n",
    "        author_str = authors[0].name\n",
    "    elif len(authors) == 2:\n",
    "        author_str = f\"{authors[0].name} and {authors[1].name}\"\n",
    "    else:\n",
    "        author_str = f\"{authors[0].name} et al.\"\n",
    "    \n",
    "    year = paper.published.year\n",
    "    title = paper.title\n",
    "    \n",
    "    reference = f\"{author_str} ({year}) '{title}', arXiv preprint arXiv:{paper.get_short_id()}.\"\n",
    "    \n",
    "    return reference\n",
    "\n",
    "def fetch_latest_papers(categories=None, max_results=None, days_back=None):\n",
    "    # Use config defaults if no parameters provided\n",
    "    if categories is None:\n",
    "        categories = ARXIV_CATEGORIES\n",
    "    if max_results is None:\n",
    "        max_results = MAX_PAPERS_TO_PROCESS\n",
    "    if days_back is None:\n",
    "        days_back = DAYS_BACK_TO_SEARCH\n",
    "        \n",
    "    client_arxiv = arxiv.Client()  # Renamed to avoid confusion with OpenAI client\n",
    "    cutoff_date = datetime.now(timezone.utc) - timedelta(days=days_back)\n",
    "    \n",
    "    category_query = \" OR \".join([f\"cat:{cat}\" for cat in categories])\n",
    "    \n",
    "    search = arxiv.Search(\n",
    "        query = f\"({category_query})\",\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.SubmittedDate\n",
    "    )\n",
    "    \n",
    "    results = list(client_arxiv.results(search))\n",
    "    recent_papers = [paper for paper in results if paper.published.replace(tzinfo=timezone.utc) > cutoff_date]\n",
    "    \n",
    "    if VERBOSE_OUTPUT:\n",
    "        print(f\"üìä Fetched {len(results)} papers, {len(recent_papers)} from last {days_back} days\")\n",
    "    \n",
    "    return recent_papers\n",
    "\n",
    "def generate_blog_post(paper):\n",
    "    authors = ', '.join([author.name for author in paper.authors])\n",
    "    prompt = f\"\"\"Write an engaging blog post about the following scientific paper:\n",
    "\n",
    "Title: {paper.title}\n",
    "Authors: {authors}\n",
    "Abstract: {paper.summary}\n",
    "\n",
    "The blog post should:\n",
    "1. Explain the main findings in simple terms\n",
    "2. Discuss potential real-world implications\n",
    "3. Be engaging and accessible to a general audience\n",
    "4. Be around {BLOG_POST_LENGTH} words long\n",
    "\n",
    "Blog Post:\"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that writes engaging blog posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=BLOG_POST_MAX_TOKENS,\n",
    "            temperature=BLOG_POST_TEMPERATURE\n",
    "        )\n",
    "        return response.choices[0].message.content.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating blog post: {e}\")\n",
    "        return None\n",
    "\n",
    "def generate_threads_post(paper, blog_post_url):\n",
    "    prompt = f\"\"\"Create a short, engaging post for Threads (max {THREADS_MAX_CHARS} characters) about this scientific paper:\n",
    "    Title: {paper.title}\n",
    "    \n",
    "    Include a brief highlight of the research and its potential impact. \n",
    "    Do not include any hashtags or 'Read more' statements.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        response = client.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant that creates engaging social media posts about scientific papers.\"},\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ],\n",
    "            max_tokens=100,\n",
    "            temperature=BLOG_POST_TEMPERATURE\n",
    "        )\n",
    "        threads_text = response.choices[0].message.content.strip().replace(\":\", \"\")\n",
    "        \n",
    "        full_post = f\"{threads_text}\\n\\n{THREADS_HASHTAGS}\\n\\nRead more: {blog_post_url}\"\n",
    "        \n",
    "        if len(full_post) > 500:\n",
    "            available_chars = 500 - len(THREADS_HASHTAGS) - len(blog_post_url) - 15\n",
    "            truncated_text = threads_text[:available_chars-3] + \"...\"\n",
    "            full_post = f\"{truncated_text}\\n\\n{THREADS_HASHTAGS}\\n\\nRead more: {blog_post_url}\"\n",
    "        \n",
    "        return full_post\n",
    "    except Exception as e:\n",
    "        print(f\"Error generating Threads post: {e}\")\n",
    "        return None\n",
    "   \n",
    "def generate_ai_image(paper, threads_post):\n",
    "    \"\"\"\n",
    "    Generate an AI image using DALL-E 3 based on the research paper\n",
    "    \"\"\"\n",
    "    # Create a more specific prompt based on the paper's content\n",
    "    # Extract key concepts from the paper title and abstract\n",
    "    title_words = paper.title.lower()\n",
    "    \n",
    "    # Determine the research domain for better image prompts\n",
    "    if any(word in title_words for word in ['neural', 'network', 'deep', 'learning', 'ai', 'artificial']):\n",
    "        domain = \"neural networks and AI\"\n",
    "        visual_style = \"futuristic digital networks with glowing nodes and connections\"\n",
    "    elif any(word in title_words for word in ['computer', 'vision', 'image', 'visual']):\n",
    "        domain = \"computer vision\"\n",
    "        visual_style = \"digital image processing with geometric patterns and visual data\"\n",
    "    elif any(word in title_words for word in ['nlp', 'language', 'text', 'linguistic']):\n",
    "        domain = \"natural language processing\"\n",
    "        visual_style = \"flowing text and language symbols transforming into digital patterns\"\n",
    "    elif any(word in title_words for word in ['robot', 'autonomous', 'control']):\n",
    "        domain = \"robotics\"\n",
    "        visual_style = \"sleek robotic elements and autonomous systems\"\n",
    "    elif any(word in title_words for word in ['data', 'analysis', 'mining']):\n",
    "        domain = \"data science\"\n",
    "        visual_style = \"abstract data visualizations and flowing information streams\"\n",
    "    else:\n",
    "        domain = \"artificial intelligence research\"\n",
    "        visual_style = \"abstract technological concepts with clean, modern design\"\n",
    "    \n",
    "    # Create a sophisticated prompt\n",
    "    prompt = f\"\"\"\n",
    "    Create a modern, professional illustration representing {domain} research. \n",
    "    The image should feature {visual_style}, using a clean and sophisticated \n",
    "    color palette with blues, purples, and subtle gradients. The style should be \n",
    "    minimalist yet engaging, suitable for a technology blog. Avoid text, people, \n",
    "    or specific logos. Focus on abstract technological concepts that convey \n",
    "    innovation and scientific progress.\n",
    "    \"\"\"\n",
    "    \n",
    "    try:\n",
    "        print(f\"Generating DALL-E 3 image for: {paper.title[:50]}...\")\n",
    "        \n",
    "        response = client.images.generate(\n",
    "            model=IMAGE_MODEL,\n",
    "            prompt=prompt,\n",
    "            n=1,\n",
    "            size=IMAGE_SIZE,\n",
    "            quality=IMAGE_QUALITY,\n",
    "            style=IMAGE_STYLE\n",
    "        )\n",
    "        \n",
    "        image_url = response.data[0].url\n",
    "        print(\"‚úÖ DALL-E 3 image generated successfully!\")\n",
    "        \n",
    "        # Display the image in the notebook (if running in Jupyter)\n",
    "        try:\n",
    "            from IPython.display import display, Image\n",
    "            display(Image(url=image_url))\n",
    "        except ImportError:\n",
    "            print(f\"Image URL: {image_url}\")\n",
    "        \n",
    "        return image_url\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error generating DALL-E 3 image: {e}\")\n",
    "        \n",
    "        # Fallback: try with a simpler prompt\n",
    "        try:\n",
    "            print(\"Trying with simplified prompt...\")\n",
    "            simple_prompt = f\"A clean, modern illustration representing {domain}, minimalist style, blue and purple gradient background\"\n",
    "            \n",
    "            response = client.images.generate(\n",
    "                model=IMAGE_MODEL,\n",
    "                prompt=simple_prompt,\n",
    "                n=1,\n",
    "                size=IMAGE_SIZE,\n",
    "                quality=IMAGE_QUALITY\n",
    "            )\n",
    "            \n",
    "            image_url = response.data[0].url\n",
    "            print(\"‚úÖ Fallback image generated successfully!\")\n",
    "            return image_url\n",
    "            \n",
    "        except Exception as e2:\n",
    "            print(f\"‚ùå Fallback also failed: {e2}\")\n",
    "            return None\n",
    "\n",
    "def download_and_save_image(image_url, paper_short_id, date):\n",
    "    \"\"\"\n",
    "    Download the AI image and save it to GitHub repository\n",
    "    This prevents the image from expiring\n",
    "    \"\"\"\n",
    "    import requests\n",
    "    import base64\n",
    "    \n",
    "    try:\n",
    "        # Download the image\n",
    "        print(\"Downloading image...\")\n",
    "        img_response = requests.get(image_url)\n",
    "        img_response.raise_for_status()\n",
    "        \n",
    "        # Create filename\n",
    "        image_filename = f\"assets/images/{date}-{paper_short_id}.png\"\n",
    "        \n",
    "        # Encode image for GitHub API\n",
    "        encoded_image = base64.b64encode(img_response.content).decode(\"utf-8\")\n",
    "        \n",
    "        # Upload to GitHub\n",
    "        url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/{image_filename}\"\n",
    "        headers = {\n",
    "            \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "            \"Accept\": \"application/vnd.github+json\",\n",
    "            \"X-GitHub-Api-Version\": \"2022-11-28\"  # Use the API version from docs\n",
    "        }\n",
    "        \n",
    "        # Always try to create as new file first (no sha parameter)\n",
    "        print(f\"üì§ Creating new file: {image_filename}\")\n",
    "        data = {\n",
    "            \"message\": f\"Add image for blog post {paper_short_id}\",\n",
    "            \"content\": encoded_image\n",
    "        }\n",
    "        \n",
    "        response = requests.put(url, headers=headers, json=data)\n",
    "        print(f\"üì• Upload response: {response.status_code}\")\n",
    "        \n",
    "        if response.status_code == 201:\n",
    "            # Successfully created new file\n",
    "            github_image_url = f\"https://{GITHUB_PAGES_SITE}/{image_filename}\"\n",
    "            print(f\"‚úÖ Image saved to GitHub: {github_image_url}\")\n",
    "            \n",
    "            # Wait for GitHub Pages to deploy the image\n",
    "            print(f\"‚è≥ Waiting for GitHub Pages to deploy image ({GITHUB_PAGES_IMAGE_WAIT} seconds)...\")\n",
    "            time.sleep(GITHUB_PAGES_IMAGE_WAIT)\n",
    "            \n",
    "            # Test if the image is accessible\n",
    "            try:\n",
    "                test_response = requests.head(github_image_url, timeout=10)\n",
    "                if test_response.status_code == 200:\n",
    "                    print(\"‚úÖ GitHub Pages image is accessible!\")\n",
    "                    return github_image_url\n",
    "                else:\n",
    "                    print(f\"‚ö†Ô∏è GitHub Pages image not ready (status: {test_response.status_code})\")\n",
    "                    print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                    return image_url\n",
    "            except Exception as e:\n",
    "                print(f\"‚ö†Ô∏è Cannot verify GitHub Pages image accessibility: {e}\")\n",
    "                print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                return image_url\n",
    "                \n",
    "        elif response.status_code == 422:\n",
    "            # File might already exist, try to update it\n",
    "            print(\"üîÑ File might exist, checking and updating...\")\n",
    "            \n",
    "            # Get the existing file info\n",
    "            check_response = requests.get(url, headers=headers)\n",
    "            if check_response.status_code == 200:\n",
    "                file_info = check_response.json()\n",
    "                print(f\"üìÑ File exists, updating with sha: {file_info['sha'][:8]}...\")\n",
    "                \n",
    "                # Update with sha\n",
    "                update_data = {\n",
    "                    \"message\": f\"Update image for blog post {paper_short_id}\",\n",
    "                    \"content\": encoded_image,\n",
    "                    \"sha\": file_info[\"sha\"]\n",
    "                }\n",
    "                \n",
    "                update_response = requests.put(url, headers=headers, json=update_data)\n",
    "                if update_response.status_code == 200:\n",
    "                    github_image_url = f\"https://{GITHUB_PAGES_SITE}/{image_filename}\"\n",
    "                    print(f\"‚úÖ Image updated on GitHub: {github_image_url}\")\n",
    "                    return github_image_url\n",
    "                else:\n",
    "                    print(f\"‚ùå Failed to update: {update_response.status_code}\")\n",
    "                    print(f\"Response: {update_response.text}\")\n",
    "                    return image_url\n",
    "            else:\n",
    "                print(f\"‚ùå Cannot check file existence: {check_response.status_code}\")\n",
    "                print(\"üìé Using original OpenAI URL as fallback\")\n",
    "                return image_url\n",
    "        else:\n",
    "            print(f\"‚ùå Failed to save image to GitHub: {response.status_code}\")\n",
    "            print(f\"Response: {response.text}\")\n",
    "            print(\"üìé Using original OpenAI URL as fallback\")\n",
    "            return image_url\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error saving image: {e}\")\n",
    "        print(\"üìé Using original OpenAI URL as fallback\")\n",
    "        return image_url\n",
    "\n",
    "def create_github_blog_post(paper, content, date, short_id, image_url):\n",
    "    # Use consistent short_id for the file name\n",
    "    file_name = f\"{date}-{short_id}.md\"\n",
    "    \n",
    "    # Generate Harvard reference\n",
    "    harvard_reference = generate_harvard_reference(paper)\n",
    "    \n",
    "    # Fixed: No indentation in front matter\n",
    "    file_content = f\"\"\"---\n",
    "layout: post\n",
    "title: \"{paper.title}\"\n",
    "date: {date} {datetime.now().strftime('%H:%M:%S +0000')}\n",
    "categories: [blog, AI, research]\n",
    "image: {image_url}\n",
    "---\n",
    "![AI Generated Image]({image_url})\n",
    "\n",
    "{content}\n",
    "\n",
    "## Original Research Paper\n",
    "For more details, please refer to the original research paper:\n",
    "[{paper.title}]({paper.entry_id})\n",
    "\n",
    "## Reference\n",
    "{harvard_reference}\n",
    "\"\"\"\n",
    "    \n",
    "    encoded_content = base64.b64encode(file_content.encode(\"utf-8\")).decode(\"utf-8\")\n",
    "    url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/_posts/{file_name}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    \n",
    "    # Check if file already exists\n",
    "    response = requests.get(url, headers=headers)\n",
    "    if response.status_code == 200:\n",
    "        print(f\"Blog post already exists: {file_name}\")\n",
    "        return False, \"\"\n",
    "\n",
    "    # File doesn't exist, create new file\n",
    "    data = {\n",
    "        \"message\": f\"Add new blog post: {paper.title}\",\n",
    "        \"content\": encoded_content\n",
    "    }\n",
    "\n",
    "    response = requests.put(url, headers=headers, json=data)\n",
    "    if response.status_code != 201:\n",
    "        print(f\"GitHub API Error: {response.status_code}\")\n",
    "        print(f\"Response content: {response.text}\")\n",
    "        return False, \"\"\n",
    "    \n",
    "    # Construct the URL based on the file name\n",
    "    post_url = f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{short_id}/\"\n",
    "    return True, post_url\n",
    "   \n",
    "\n",
    "def check_existing_post(short_id, date):\n",
    "    file_name = f\"{date}-{short_id}.md\"\n",
    "    url = f\"https://api.github.com/repos/{GITHUB_REPO}/contents/_posts/{file_name}\"\n",
    "    headers = {\n",
    "        \"Authorization\": f\"token {GITHUB_TOKEN}\",\n",
    "        \"Accept\": \"application/vnd.github.v3+json\"\n",
    "    }\n",
    "    response = requests.get(url, headers=headers)\n",
    "    return response.status_code == 200\n",
    "\n",
    "def create_media_container(access_token, user_id, text, image_url):\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads\"\n",
    "    \n",
    "    params = {\n",
    "        \"media_type\": \"IMAGE\",\n",
    "        \"image_url\": image_url,\n",
    "        \"text\": text,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Create Media Container Status Code: {response.status_code}\")\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error creating media container: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Response content: {e.response.text}\")\n",
    "        return None\n",
    "\n",
    "def publish_thread(access_token, user_id, creation_id):\n",
    "    url = f\"https://graph.threads.net/v1.0/{user_id}/threads_publish\"\n",
    "    \n",
    "    params = {\n",
    "        \"creation_id\": creation_id,\n",
    "        \"access_token\": access_token\n",
    "    }\n",
    "    \n",
    "    try:\n",
    "        response = requests.post(url, params=params)\n",
    "        response.raise_for_status()\n",
    "        print(f\"Publish Thread Status Code: {response.status_code}\")\n",
    "        return response.json()\n",
    "    except requests.RequestException as e:\n",
    "        print(f\"Error publishing thread: {e}\")\n",
    "        if hasattr(e, 'response') and e.response is not None:\n",
    "            print(f\"Response content: {e.response.text}\")\n",
    "        return None\n",
    "\n",
    "def post_to_threads(text, image_url, access_token, user_id, initial_wait=30, max_retries=3):\n",
    "    for attempt in range(max_retries):\n",
    "        try:\n",
    "            # Step 1: Create media container\n",
    "            container = create_media_container(access_token, user_id, text, image_url)\n",
    "            if container is None or 'id' not in container:\n",
    "                print(\"Failed to create media container.\")\n",
    "                return False\n",
    "\n",
    "            container_id = container['id']\n",
    "            print(f\"Media container created with ID: {container_id}\")\n",
    "\n",
    "            # Wait before publishing\n",
    "            print(f\"Waiting {initial_wait} seconds before publishing...\")\n",
    "            time.sleep(initial_wait)\n",
    "\n",
    "            # Step 2: Publish the thread\n",
    "            publish_result = publish_thread(access_token, user_id, container_id)\n",
    "            if publish_result is None or 'id' not in publish_result:\n",
    "                print(\"Failed to publish thread.\")\n",
    "                return False\n",
    "\n",
    "            print(f\"Successfully posted to Threads with ID: {publish_result['id']}\")\n",
    "            return True\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error posting to Threads: {e}\")\n",
    "            \n",
    "            if attempt < max_retries - 1:\n",
    "                print(f\"Retrying in {initial_wait} seconds...\")\n",
    "                time.sleep(initial_wait)\n",
    "            else:\n",
    "                print(\"Max retries reached. Failed to post to Threads.\")\n",
    "                return False\n",
    "\n",
    "    return False\n",
    "\n",
    "def main():\n",
    "    try:\n",
    "        if VERBOSE_OUTPUT:\n",
    "            print(\"üöÄ Starting automated blog creation process...\")\n",
    "            print(f\"üìù Configuration: {MAX_PAPERS_TO_PROCESS} papers, {DAYS_BACK_TO_SEARCH} days back\")\n",
    "            print(f\"üîç Categories: {', '.join(ARXIV_CATEGORIES)}\")\n",
    "        \n",
    "        papers = fetch_latest_papers()\n",
    "        if not papers:\n",
    "            print(f\"No recent papers found in categories: {ARXIV_CATEGORIES}\")\n",
    "            return\n",
    "\n",
    "        processed_count = 0\n",
    "        for paper in papers:\n",
    "            display(Markdown(f\"## Processing: {paper.title}\"))\n",
    "            \n",
    "            short_id = hashlib.md5(paper.title.encode()).hexdigest()[:8]\n",
    "            \n",
    "            date = datetime.now().strftime(\"%Y-%m-%d\")\n",
    "            if SKIP_EXISTING_POSTS and check_existing_post(short_id, date):\n",
    "                print(f\"Blog post already exists for: {paper.title}\")\n",
    "                print(\"Skipping to next paper...\")\n",
    "                continue\n",
    "\n",
    "            blog_post = generate_blog_post(paper)\n",
    "            if not blog_post:\n",
    "                print(f\"Failed to generate blog post for: {paper.title}\")\n",
    "                print(\"Skipping to next paper...\")\n",
    "                continue\n",
    "\n",
    "            display(Markdown(f\"### Original Paper: [{paper.entry_id}]({paper.entry_id})\"))\n",
    "            display(Markdown(blog_post))\n",
    "            \n",
    "            # Generate a temporary post URL\n",
    "            temp_post_url = f\"https://{GITHUB_PAGES_SITE}/{date.replace('-', '/')}/{short_id}/\"\n",
    "            \n",
    "            # Generate Threads post first\n",
    "            threads_post = generate_threads_post(paper, temp_post_url)\n",
    "            if not threads_post:\n",
    "                print(\"Failed to generate Threads post. Skipping to next paper...\")\n",
    "                continue\n",
    "            \n",
    "            # Generate image based on paper content\n",
    "            image_url = generate_ai_image(paper, threads_post)\n",
    "            if not image_url:\n",
    "                print(\"Failed to generate AI image. Skipping to next paper...\")\n",
    "                continue\n",
    "            \n",
    "            # Download and save the image to prevent expiration\n",
    "            if SAVE_IMAGES_TO_GITHUB:\n",
    "                image_url = download_and_save_image(image_url, short_id, date)\n",
    "            \n",
    "            # Create GitHub blog post with the generated image\n",
    "            success, post_url = create_github_blog_post(paper, blog_post, date, short_id, image_url)\n",
    "            \n",
    "            if success:\n",
    "                print(f\"Successfully created blog post on GitHub: {post_url}\")\n",
    "                \n",
    "                # Add delay to allow for link preview generation\n",
    "                print(f\"Waiting {LINK_PREVIEW_WAIT} seconds for link preview generation...\")\n",
    "                time.sleep(LINK_PREVIEW_WAIT)\n",
    "                \n",
    "                # Update the Threads post with the correct URL if it changed\n",
    "                if post_url != temp_post_url:\n",
    "                    threads_post = threads_post.replace(temp_post_url, post_url)\n",
    "                \n",
    "                display(Markdown(f\"### Threads Post:\\n{threads_post}\"))\n",
    "                if post_to_threads(threads_post, image_url, THREADS_ACCESS_TOKEN, THREADS_USER_ID, THREADS_WAIT_TIME, THREADS_MAX_RETRIES):\n",
    "                    print(\"Successfully posted to Threads with image!\")\n",
    "                else:\n",
    "                    print(\"Failed to post to Threads.\")\n",
    "                \n",
    "                processed_count += 1\n",
    "            else:\n",
    "                print(\"Failed to create blog post on GitHub.\")\n",
    "        \n",
    "        if VERBOSE_OUTPUT:\n",
    "            print(f\"\\n‚úÖ Processing complete! Created {processed_count} new blog posts.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
